import os
from dotenv import load_dotenv
from langchain.chains import RetrievalQA
from langchain.llms import OpenAI
try:
    from langchain_google_genai import ChatGoogleGenerativeAI
except ImportError:
    print("‚ö†Ô∏è langchain-google-genai not installed. Install with: pip install langchain-google-genai")
    ChatGoogleGenerativeAI = None

from pre_doc import vector_store

# Load environment variables
load_dotenv('config.env')


def create_qa_chain(model_type="openai"):
    """
    T·∫°o QA chain v·ªõi c√°c API model kh√°c nhau
    model_type: "openai", "gemini"
    """

    if model_type == "openai":
        # S·ª≠ d·ª•ng OpenAI API
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key or api_key == 'your_openai_api_key_here':
            raise ValueError(
                "Vui l√≤ng c·∫•u h√¨nh OPENAI_API_KEY trong file config.env")

        llm = OpenAI(
            temperature=0.7,
            openai_api_key=api_key,
            max_tokens=500
        )
        print("ü§ñ S·ª≠ d·ª•ng OpenAI GPT API")

    elif model_type == "gemini":
        # S·ª≠ d·ª•ng Gemini API
        if ChatGoogleGenerativeAI is None:
            raise ImportError(
                "C·∫ßn c√†i ƒë·∫∑t: pip install langchain-google-genai")

        api_key = os.getenv('GEMINI_API_KEY')
        if not api_key or api_key == 'your_gemini_api_key_here':
            raise ValueError(
                "Vui l√≤ng c·∫•u h√¨nh GEMINI_API_KEY trong file config.env")

        # Th·ª≠ c√°c model Gemini theo th·ª© t·ª± ∆∞u ti√™n
        gemini_models = [
            "gemini-2.0-flash-exp",  # Model m·ªõi nh·∫•t
            "gemini-1.5-flash",      # Backup option
            "gemini-1.5-pro",        # Fallback
            "gemini-pro"             # Legacy (c√≥ th·ªÉ kh√¥ng ho·∫°t ƒë·ªông)
        ]

        llm = None
        last_error = None

        for model_name in gemini_models:
            try:
                llm = ChatGoogleGenerativeAI(
                    model=model_name,
                    google_api_key=api_key,
                    temperature=0.7,
                    convert_system_message_to_human=True
                )
                print(f"ü§ñ S·ª≠ d·ª•ng Google Gemini API: {model_name}")
                break
            except Exception as e:
                last_error = e
                print(f"‚ö†Ô∏è Model {model_name} kh√¥ng kh·∫£ d·ª•ng: {e}")
                continue

        if llm is None:
            raise ValueError(
                f"‚ùå Kh√¥ng th·ªÉ kh·ªüi t·∫°o b·∫•t k·ª≥ model Gemini n√†o. L·ªói cu·ªëi: {last_error}")

    else:
        raise ValueError(
            f"Model type '{model_type}' kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£. Ch·ªçn: 'openai' ho·∫∑c 'gemini'")

    # T·∫°o QA chain
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=vector_store.as_retriever(search_kwargs={"k": 10}),
        return_source_documents=True
    )

    return qa_chain


def initialize_default_chain():
    """Kh·ªüi t·∫°o chain m·∫∑c ƒë·ªãnh, th·ª≠ OpenAI tr∆∞·ªõc, n·∫øu kh√¥ng c√≥ th√¨ Gemini"""

    # Th·ª≠ Gemini tr∆∞·ªõc (v√¨ c√≥ API key v√† free)
    try:
        gemini_key = os.getenv('GEMINI_API_KEY')
        if gemini_key and gemini_key != 'your_gemini_api_key_here':
            return create_qa_chain("gemini")
    except Exception as e:
        print(f"‚ö†Ô∏è Gemini kh√¥ng kh·∫£ d·ª•ng: {e}")

    # Th·ª≠ OpenAI
    try:
        openai_key = os.getenv('OPENAI_API_KEY')
        if openai_key and openai_key != 'your_openai_api_key_here':
            return create_qa_chain("openai")
    except Exception as e:
        print(f"‚ö†Ô∏è OpenAI kh√¥ng kh·∫£ d·ª•ng: {e}")

    raise ValueError(
        "‚ùå Kh√¥ng c√≥ API key h·ª£p l·ªá. Vui l√≤ng c·∫•u h√¨nh OPENAI_API_KEY ho·∫∑c GEMINI_API_KEY")


# Kh·ªüi t·∫°o qa_chain m·∫∑c ƒë·ªãnh
try:
    qa_chain = initialize_default_chain()
    print("‚úÖ ƒê√£ kh·ªüi t·∫°o chatbot th√†nh c√¥ng")
except Exception as e:
    print(f"‚ùå L·ªói kh·ªüi t·∫°o: {e}")
    qa_chain = None
